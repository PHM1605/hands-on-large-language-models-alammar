{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8ddf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phm/anaconda3/envs/python310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.05s/it]\n",
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76768074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why did the chicken join the band? Because it had the drumsticks!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"Create a funny joke about chickens\"\n",
    "    }\n",
    "]\n",
    "output = pipe(messages)\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6878969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Create a funny joke about chickens<|end|>\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Check internally converted prompt\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ebe4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why do chickens hate going to school? Because it’s really difficult to follow their teacher!\n"
     ]
    }
   ],
   "source": [
    "# Using a high temperature\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "output = pipe(messages, do_sample=True, temperature=1)\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b003c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why don’t chickens use mobile phones? Because they prefer to “peck” at their eggs rather than touch keys!\n"
     ]
    }
   ],
   "source": [
    "# Use a high top_p (more choices of output samples can be chosen)\n",
    "output = pipe(messages, do_sample=True, top_p=1)\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed5ff4",
   "metadata": {},
   "source": [
    "## In-Context Learning: providing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a5a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "A 'Gigamuru' is a type of Japanese musical instrument. An example of a sentence that uses the word Gigamuru is:<|end|>\n",
      "<|assistant|>\n",
      "I have a Gigamuru that my uncle gave me as a gift. I love to play it at home.<|end|>\n",
      "<|user|>\n",
      "To 'screeg' something is to swing a sword at it. An example of a sentence that uses the word screeg is:<|end|>\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Goal: generate a sentence with a made-up fancy word\n",
    "one_shot_prompt = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"A 'Gigamuru' is a type of Japanese musical instrument. An example of a sentence that uses the word Gigamuru is:\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I have a Gigamuru that my uncle gave me as a gift. I love to play it at home.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"To 'screeg' something is to swing a sword at it. An example of a sentence that uses the word screeg is:\"\n",
    "    }\n",
    "]\n",
    "# Check which template Phi-3 converts this prompt to\n",
    "print(tokenizer.apply_chat_template(one_shot_prompt, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644642be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " During the duel, the knight attempted to screeg his opponent, but he was skilled enough to dodge and counter the strikes.\n"
     ]
    }
   ],
   "source": [
    "# Generate sentence \n",
    "outputs = pipe(one_shot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddac66d",
   "metadata": {},
   "source": [
    "## Chain prompting: breaking up the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65212714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Name: Chattermind AI\n",
      "Slogan: \"Unleashing the power of LLMs for conversational magic.\"\n"
     ]
    }
   ],
   "source": [
    "product_prompt = [\n",
    "    {\"role\":\"user\", \n",
    "     \"content\":\"Create a name and slogan for a chatbot that leverages LLMs.\"}\n",
    "]\n",
    "outputs = pipe(product_prompt)\n",
    "product_description = outputs[0][\"generated_text\"]\n",
    "print(product_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9d3137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Transform your business with Chattermind AI! Embrace the future of communication with our \"Unleashing the power of LLMs for conversational magic\". Experience cutting-edge AI technology that delivers engaging, consistent, and intelligent conversations. Elevate your customer experience and unlock unlimited opportunities with Chattermind AI today!\n"
     ]
    }
   ],
   "source": [
    "# chaining to the next prompt, generate a sales pitch}\n",
    "sales_prompt = [\n",
    "    {\"role\":\"user\", \"content\":f\"Generate a very short sales pitch for the following product: '{product_description}'\"}\n",
    "]\n",
    "outputs = pipe(sales_prompt)\n",
    "sales_pitch = outputs[0][\"generated_text\"]\n",
    "print(sales_pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f518ce79",
   "metadata": {},
   "source": [
    "## Chain-of-thought: think before answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e434c32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The cafeteria had 23 apples. They used 20 to make lunch, so there were 23 - 20 = 3 apples left. Then they bought 6 more apples, which would bring the total to 3 + 6 = 9 apples. The answer is 9.\n"
     ]
    }
   ],
   "source": [
    "# Answering with the chain of thought\n",
    "cot_prompt = [\n",
    "    {\"role\":\"user\", \"content\":\"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\"},\n",
    "    {\"role\":\"assistant\", \"content\":\"Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5+6=11. The answer is 11.\"},\n",
    "    {\"role\":\"user\", \"content\":\"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"}\n",
    "]\n",
    "outputs = pipe(cot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc1fb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1: Find out how many apples are left after using 20 apples.\n",
      "The cafeteria started with 23 apples and used 20 for lunch.\n",
      "23 apples - 20 apples = 3 apples left\n",
      "\n",
      "Step 2: Add the extra 6 apples bought to the remaining apples.\n",
      "The cafeteria had 3 apples left and bought 6 more.\n",
      "3 apples + 6 apples = 9 apples\n",
      "\n",
      "So, the cafeteria now has 9 apples.\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot chain-of-thought\n",
    "zeroshot_cot_prompt = [\n",
    "    {\"role\":\"user\", \"content\":\"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have? Let's think step-by-step.\"}\n",
    "]\n",
    "outputs = pipe(zeroshot_cot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17157bed",
   "metadata": {},
   "source": [
    "## Tree-of-thought: mimic EXPERTS discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "580cc74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Expert 1:\n",
      "\n",
      "Step 1: Start by acknowledging the initial number of apples in the cafeteria. (23 apples)\n",
      "\n",
      "Step 2: Subtract the number of apples used for making lunch (23 - 20 = 3 apples left).\n",
      "\n",
      "Step 3: Add the number of apples bought (3 + 6 = 9 apples).\n",
      "\n",
      "Expert 1's final answer: The cafeteria now has 9 apples.\n",
      "\n",
      "Expert 2:\n",
      "\n",
      "Step 1: Identify the starting point, which is the number of apples the cafeteria had initially (23 apples).\n",
      "\n",
      "Step 2: Subtract the number of apples used to make the lunch (23 - 20 = 3 apples).\n",
      "\n",
      "Step 3: Add the total number of apples bought (3 + 6 = 9 apples).\n",
      "\n",
      "Expert 2's final answer: The cafeteria now has 9 apples.\n",
      "\n",
      "Expert 3:\n",
      "\n",
      "Step 1: Note the beginning amount of apples in the cafeteria (23 apples).\n",
      "\n",
      "Step 2: Subtract the 20 apples used for making lunch (23 - 20 = 3 apples).\n",
      "\n",
      "Step 3: Add the 6 apples bought to the remaining apples (3 + 6 = 9 apples).\n",
      "\n",
      "Expert 3's final answer: The cafeteria has 9 apples now.\n",
      "\n",
      "Summary/Discussion:\n",
      "\n",
      "All three experts agreed that the cafeteria now has 9 apples. They all shared their reasoning process, which involves the initial count of apples, deducting those used for lunch, and later adding the apples bought. None of them deviated from this approach, so none of the experts had to leave the discussion.\n"
     ]
    }
   ],
   "source": [
    "zeroshot_tot_prompt = [\n",
    "    {\n",
    "        \"role\":\"user\", \n",
    "        \"content\":\"\"\"\n",
    "        Imagine three different experts are answering this question.\n",
    "        All experts will write down 1 step of their thinking, then share it with the group.\n",
    "        Then all experts will go on to the next step, etc. \n",
    "        If any expert realizes they're wrong at any poing then they leave.\n",
    "        The question is 'The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?'\n",
    "        Make sure to discuss the results.\n",
    "        \"\"\"}\n",
    "]\n",
    "outputs = pipe(zeroshot_tot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb356c",
   "metadata": {},
   "source": [
    "# Output verification\n",
    "(there is 3rd method of FINE-TUNING, which is not covered here but later)\n",
    "## Providing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42949c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ```json\n",
      "{\n",
      "  \"name\": \"Eldrid the Brave\",\n",
      "  \"age\": 25,\n",
      "  \"species\": \"Human\",\n",
      "  \"class_type\": \"Warrior\",\n",
      "  \"race\": \"Human\",\n",
      "  \"gender\": \"Male\",\n",
      "  \"appearance\": {\n",
      "     \"height\": \"180 cm\",\n",
      "     \"weight\": \"80 kg\",\n",
      "     \"age_indicator\": \"Young\",\n",
      "     \"body_type\": \"Muscular\",\n",
      "     \"facial_features\": {\n",
      "       \"eyes\": \"Brown\",\n",
      "       \"hair_color\": \"Black\",\n",
      "       \"hair_style\": \"Shaven\",\n",
      "       \"facial_hair\": \"Slight stubble\"\n",
      "     },\n",
      "     \"clothing\": {\n",
      "       \"armor\": \"Chainmail\",\n",
      "       \"boots\": \"Leather\",\n",
      "       \"weapons\": {\n",
      "         \"primary\": \"Two-handed Axe\",\n",
      "         \"secondary\": \"Short sword\"\n",
      "       }\n",
      "     }\n",
      "  },\n",
      "  \"personality_traits\": [\n",
      "     \"Brave\",\n",
      "     \"Loyal\",\n",
      "     \"Determined\",\n",
      "     \"Fierce\"\n",
      "  ],\n",
      "  \"skills\": {\n",
      "     \"melee_combat\": 100,\n",
      "     \"long_range_combat\": 20,\n",
      "     \"stealth\": 50,\n",
      "     \"magic\": 10\n",
      "  },\n",
      "  \"background\": \"Eldrid was born into a noble family in the city-state of Arden. As a child, he showed a natural talent for combat and quickly rose through the ranks of the city's military. Eventually, Eldrid became a commander in the King's Guard, leading his men to victory in several battles against the neighboring kingdoms. However, after discovering that his family was involved in a plot to overthrow the King, Eldrid took it upon himself to prove his loyalty and protect the kingdom from within.\",\n",
      "  \"current_quest\": \"Eldrid must investigate a mysterious disappearance in the nearby village of Glenwood. He must interrogate the villagers, search for clues, and ultimately un\n"
     ]
    }
   ],
   "source": [
    "# Create a character profile for a RPG game - zeroshot\n",
    "zeroshot_prompt = [\n",
    "    {\"role\":\"user\",\n",
    "    \"content\":\"Create a character profile for an RPG game in JSON format.\"}\n",
    "]\n",
    "outputs = pipe(zeroshot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd0ee93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ```\n",
      "\n",
      "{\n",
      "\n",
      "    \"description\": \"A sagacious and battle-hardened druid, deeply connected to the mystical forces of nature, bound by a sacred oath to protect the ancient woods.\",\n",
      "\n",
      "    \"name\": \"Aranel Windwhisper\",\n",
      "\n",
      "    \"armor\": \"Sylvan Cloak\",\n",
      "\n",
      "    \"weapon\": \"Yew Bow, Silver Arrow, Nature's Whisper Staff\"\n",
      "\n",
      "}\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Create a character profile for a RPG game - oneshot\n",
    "one_shot_template = \"\"\" Create a short character profile for an RPG game. Make sure to only use this format:\n",
    "{\n",
    "    \"description\": \"A SHORT DESCRIPTION\",\n",
    "    \"name\": \"THE CHARACTER'S NAME\",\n",
    "    \"armor\": \"ONE PIECE OF ARMOR\",\n",
    "    \"weapon\": \"ONE OR MORE WEAPONS\"\n",
    "}\n",
    "\"\"\"\n",
    "one_shot_prompt = [\n",
    "    {\"role\":\"user\",\"content\":one_shot_template}\n",
    "]\n",
    "outputs = pipe(one_shot_prompt)\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999ef1f",
   "metadata": {},
   "source": [
    "## Grammar: constrained sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef6a91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning VRAM off the old model first\n",
    "import gc, torch\n",
    "del model, tokenizer, pipe\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0524ffd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp.llama import Llama\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct-gguf\",\n",
    "    filename=\"*fp16.gguf\",\n",
    "    n_gpu_layers=-1, # all layers of model will be on GPU\n",
    "    n_ctx=2048, # context size\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "453216da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"warrior\": {\n",
      "        \"name\": \"Eldric Stormbringer\",\n",
      "        \"class\": \"Warrior\",\n",
      "        \"level\": 5,\n",
      "        \"attributes\": {\n",
      "            \"strength\": 18,\n",
      "            \"dexterity\": 10,\n",
      "            \"constitution\": 16,\n",
      "            \"intelligence\": 8,\n",
      "            \"wisdom\": 10,\n",
      "            \"charisma\": 12\n",
      "        },\n",
      "        \"skills\": [\n",
      "            {\n",
      "                \"name\": \"Martial Arts\",\n",
      "                \"proficiency\": 20,\n",
      "                \"description\": \"Expert in hand-to-hand combat and weapon handling.\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"Shield Block\",\n",
      "                \"proficiency\": 18,\n",
      "                \"description\": \"Highly skilled at deflecting attacks with a shield.\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"Heavy Armor\",\n",
      "                \"proficiency\": 16,\n",
      "                \"description\": \"Expertly equipped with heavy armor for protection.\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"Survival\",\n",
      "                \"proficiency\": 14,\n",
      "                \"description\": \"Adept at finding food, water, and shelter in the wilderness.\"\n",
      "            }\n",
      "        ],\n",
      "        \"equipment\": [\n",
      "            {\n",
      "                \"name\": \"Iron Sword\",\n",
      "                \"type\": \"Weapon\",\n",
      "                \"damage\": 12,\n",
      "                \"durability\": 100\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"Chainmail Armor\",\n",
      "                \"type\": \"Armor\",\n",
      "                \"defense\": 18,\n",
      "                \"durability\": 100\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"Leather Boots\",\n",
      "                \"type\": \"Armor\",\n",
      "                \"defense\": 8,\n",
      "                \"durability\": 100\n",
      "            }\n",
      "        ],\n",
      "        \"abilities\": [\n",
      "            {\n",
      "                \"name\": \"Berserker Rage\",\n",
      "                \"description\": \"Increases strength and attack power for a short duration.\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"Shield Wall\",\n",
      "                \"description\": \"Forms a defensive barrier with allies, reducing incoming damage.\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"Battle Cry\",\n",
      "                \"description\": \"Inspires nearby allies, increasing their attack power temporarily.\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ask model to create RPG character in JSON format\n",
    "output = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\":\"user\", \"content\":\"Create a warrior for an RPG in JSON format.\"}\n",
    "    ],\n",
    "    response_format={\"type\":\"json_object\"},\n",
    "    temperature=0\n",
    ")[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# to check if output is indeed a json => convert <json> to <string> and reconvert to <json> to check\n",
    "import json\n",
    "json_output = json.dumps(json.loads(output), indent=4)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67940c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python310)",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
