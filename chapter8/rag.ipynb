{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b852de2-93db-4e13-a1bb-fdcc6ec543c8",
   "metadata": {},
   "source": [
    "# Semantic Search and Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c30e6-0fa1-4644-af84-64714beb4f58",
   "metadata": {},
   "source": [
    "## Dense Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c078dbed-89ed-4910-a8f7-baeaf8fb39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere # semantic search library\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416ec53a-aebd-4964-ace3-df2849bc696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    Interstellar is a 2014 epic science fiction film directed by Christopher Nolan, who co-wrote the screenplay with his brother Jonathan Nolan. It features an ensemble cast led by Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, and Michael Caine. Set in a dystopian future where Earth is suffering from catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
    "    The screenplay had its origins in a script that Jonathan had developed in 2007 and was originally set to be directed by Steven Spielberg. Theoretical physicist Kip Thorne was an executive producer and scientific consultant on the film, and wrote the tie-in book The Science of Interstellar. It was Lynda Obst's final film as producer before her death. Cinematographer Hoyte van Hoytema shot it on 35 mm film in the Panavision anamorphic format and IMAX 70 mm. Filming began in late 2013 and took place in Alberta, Klaustur, and Los Angeles. Interstellar uses extensive practical and miniature effects, and the company DNEG created additional visual effects.\n",
    "    Interstellar premiered at the TCL Chinese Theatre on October 26, 2014, and was released in theaters in the United States on November 5, and in the United Kingdom on November 7. In the United States, it was first released on film stock, expanding to venues using digital projectors. It was a commercial success, grossing $681 million worldwide during its initial theatrical run, and $771 million worldwide with subsequent releases, making it the 10th-highest-grossing film of 2014. The film received generally positive reviews from critics. Among its various accolades, Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects.\"\"\"\n",
    "# split to list of sentences\n",
    "texts = text.split('.')\n",
    "# remove empty spaces and new lines from that list of sentences\n",
    "texts = [t.strip(' \\n') for t in texts if len(t.strip(' \\n'))>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8988b076-8470-4279-a59b-7298fc9236f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 4096)\n"
     ]
    }
   ],
   "source": [
    "# get embeddings of those sentences\n",
    "response = co.embed(\n",
    "    texts=texts,\n",
    "    input_type=\"search_document\"\n",
    ").embeddings \n",
    "embeds = np.array(response) # (num_sentences,embed_dim)=(14,4096)\n",
    "print(embeds.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99a5123-56cd-462c-8372-59fc85a6026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Build <search-index> (embedding storage)\n",
    "# conda install -c conda-forge faiss-cpu\n",
    "import faiss \n",
    "dim = embeds.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "print(index.is_trained)\n",
    "index.add(np.float32(embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ec7e3c-c3c6-40b7-a787-9701588fbc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<faiss.swigfaiss.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x792c944c3450> >\n"
     ]
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73412fba-7e00-4bf0-9008-d53576bab6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'how precise was the science'\n",
      "Nearest neighbors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interstellar uses extensive practical and mini...</td>\n",
       "      <td>11992.240234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theoretical physicist Kip Thorne was an execut...</td>\n",
       "      <td>12403.667969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cinematographer Hoyte van Hoytema shot it on 3...</td>\n",
       "      <td>12689.907227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts      distance\n",
       "0  Interstellar uses extensive practical and mini...  11992.240234\n",
       "1  Theoretical physicist Kip Thorne was an execut...  12403.667969\n",
       "2  Cinematographer Hoyte van Hoytema shot it on 3...  12689.907227"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the most similar <sentence> of that <query> term\n",
    "def search(query, number_of_results=3):\n",
    "    query_embed = co.embed(\n",
    "        texts=[query], \n",
    "        input_type=\"search_query\"\n",
    "    ).embeddings[0] # list of 4096 numbers\n",
    "    query_embed = np.float32([query_embed]) # (1,4096)\n",
    "    distances, similar_item_ids = index.search(query_embed, number_of_results) # each (1,3)\n",
    "    # format the result\n",
    "    texts_np = np.array(texts) # convert list to array of strings\n",
    "    # [0] will return 3 elements (3 rows)\n",
    "    results = pd.DataFrame(data={'texts': texts_np[similar_item_ids[0]], 'distance': distances[0]})\n",
    "\n",
    "    print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
    "    return results\n",
    "    \n",
    "query = \"how precise was the science\"\n",
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9076f2ae-e779-47e9-b6b0-3e1b00cc271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with a keyword search algorithm called BM25\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string \n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split(): # token = each word\n",
    "        token = token.strip(string.punctuation)\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc # list of significant words e.g. [\"precise\",\"science\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "753bf5c7-4562-4677-8b79-6ead1fd69360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 72944.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenized_scopus: [['interstellar', '2014', 'epic'],['science', 'fiction'],...] for each sentence\n",
    "# we have 14 sentences\n",
    "tokenized_scopus = [] \n",
    "for passage in tqdm(texts):\n",
    "    tokenized_scopus.append(bm25_tokenizer(passage))\n",
    "bm25 = BM25Okapi(tokenized_scopus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f30e5ca1-ec70-4772-b2b3-d44733f44ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: how precise was the science\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t1.548\tTheoretical physicist Kip Thorne was an executive producer and scientific consultant on the film, and wrote the tie-in book The Science of Interstellar\n",
      "\t1.548\tInterstellar is a 2014 epic science fiction film directed by Christopher Nolan, who co-wrote the screenplay with his brother Jonathan Nolan\n",
      "\t0.000\tSet in a dystopian future where Earth is suffering from catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind\n"
     ]
    }
   ],
   "source": [
    "def keyword_search(query, top_k=3, num_candidates=5):\n",
    "    print(\"Input question:\", query)\n",
    "    # BM25 search (lexical search)\n",
    "    # list of 14 scores (how match the query term to each sentence)\n",
    "    bm25_scores = bm25.get_scores(\n",
    "        bm25_tokenizer(query) # list of significant words e.g. [\"precise\",\"science\"]\n",
    "    )\n",
    "    # <argpartition> means only ensure the last N elements are INDICES OF the N largest (unlike <argsort> will sort all)\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id':idx, 'score':bm25_scores[idx]} for idx in top_n]\n",
    "    # here we sort from highest to lowest score\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    # printing out\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit[\"score\"], texts[hit[\"corpus_id\"]].replace(\"\\n\",\" \")))\n",
    "\n",
    "keyword_search(query=\"how precise was the science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5610995-a61b-4f3f-9963-db20e5c87a2c",
   "metadata": {},
   "source": [
    "## Reranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa5aa42c-d8c9-4d7a-8887-bf89c449a487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.05418382 It was a commercial success, grossing $681 million worldwide during its initial theatrical run, and $771 million worldwide with subsequent releases, making it the 10th-highest-grossing film of 2014\n",
      "1 0.041684147 Theoretical physicist Kip Thorne was an executive producer and scientific consultant on the film, and wrote the tie-in book The Science of Interstellar\n",
      "2 0.03588415 It features an ensemble cast led by Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, and Michael Caine\n"
     ]
    }
   ],
   "source": [
    "# input: <search-query> & some <search-results> \n",
    "# output: <sorted-search-results>\n",
    "query = \"how precise was the science\"\n",
    "results = co.rerank(query=query, documents=texts, top_n=3, return_documents=True)\n",
    "# printing\n",
    "for idx, result in enumerate(results.results):\n",
    "    print(idx, result.relevance_score, result.document.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d598a4c-0fad-4fad-9be1-2cc46969f6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: how precise was the science\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t1.548\tTheoretical physicist Kip Thorne was an executive producer and scientific consultant on the film, and wrote the tie-in book The Science of Interstellar\n",
      "\t1.548\tInterstellar is a 2014 epic science fiction film directed by Christopher Nolan, who co-wrote the screenplay with his brother Jonathan Nolan\n",
      "\t0.000\tCinematographer Hoyte van Hoytema shot it on 35 mm film in the Panavision anamorphic format and IMAX 70 mm\n",
      "\n",
      "Top-3 hits by rank-API (10 BM25 hits re-ranked)\n",
      "\t0.042\tTheoretical physicist Kip Thorne was an executive producer and scientific consultant on the film, and wrote the tie-in book The Science of Interstellar\n",
      "\t0.036\tIt features an ensemble cast led by Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, and Michael Caine\n",
      "\t0.035\tInterstellar is a 2014 epic science fiction film directed by Christopher Nolan, who co-wrote the screenplay with his brother Jonathan Nolan\n"
     ]
    }
   ],
   "source": [
    "# Note: we must SHORTLIST before rerank => use KEYWORD SEARCH first to get top 10 result\n",
    "# => then we RERANK top3 from that top10\n",
    "def keyword_and_reranking_search(query, top_k=3, num_candidates=10):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ## Scores based on BM25 lexical search\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query)) # (num_sentences,)\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:] # (10,) indices of the highest scores sentences\n",
    "    bm25_hits = [{'corpus_id':idx, 'score':bm25_scores[idx]} for idx in top_n]\n",
    "    # sort in descending order of scores (10 elements)\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x:x['score'], reverse=True)\n",
    "    # print out\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "\n",
    "    ## Scores based on Cohere reranking\n",
    "    docs = [texts[hit['corpus_id']] for hit in bm25_hits]\n",
    "    print(f\"\\nTop-3 hits by rank-API ({len(bm25_hits)} BM25 hits re-ranked)\")\n",
    "    results = co.rerank(query=query, documents=docs, top_n=top_k, return_documents=True)\n",
    "    # print out\n",
    "    for hit in results.results:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit.relevance_score, hit.document.text.replace(\"\\n\", \" \")))\n",
    "\n",
    "keyword_and_reranking_search(query=\"how precise was the science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06619f59-675e-4ac4-85db-e4063c617b81",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648be08d-b1ba-4507-bd44-9820a2bf8a34",
   "metadata": {},
   "source": [
    "### RAG with LLM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ed464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:'income generated'\n",
      "Nearest neighbors:\n",
      "                                               texts      distance\n",
      "0  It was a commercial success, grossing $681 mil...  14051.174805\n",
      "1  Interstellar uses extensive practical and mini...  15098.763672\n",
      "2  Theoretical physicist Kip Thorne was an execut...  15362.929688\n"
     ]
    }
   ],
   "source": [
    "query = \"income generated\"\n",
    "# 1/ Retrieval\n",
    "results = search(query) # index search with <faiss> => return a table of 3 rows, cols <texts>/<distance>\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9bcc036-eb80-4e10-8522-34e1d5bfc999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The film generated $681 million worldwide during its initial theatrical run, and $771 million worldwide with subsequent releases.\n"
     ]
    }
   ],
   "source": [
    "# 2/ Grounded generation\n",
    "docs_dict = [{'text':text} for text in results['texts']] # [{'text':'abcf dsf'}, {'text':'xyz zz'}, ]\n",
    "response = co.chat(\n",
    "    message=query,\n",
    "    documents=docs_dict\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74456323-6c22-4b9e-ad1e-69fe809261f7",
   "metadata": {},
   "source": [
    "### RAG with local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1949640f-b773-4d47-b2d6-8de5c6216736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a742e7f-b4b7-47b6-8860-79e5206ae57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding model\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='thenlper/gte-small'\n",
    ")\n",
    "# use embedding model to setup vector database\n",
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_texts(texts, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c7f6c6f-5334-4974-b53a-c9a1d9e05754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "# Load the generation model\n",
    "from langchain import LlamaCpp\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"Phi-3-mini-4k-instruct-fp16.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    max_tokens=500,\n",
    "    n_ctx=2048,\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d066d0f-3c06-4e92-8f45-8335e0bfbe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Income generated',\n",
       " 'result': \" Interstellar generated a worldwide income of $771 million with subsequent releases.\\n\\nThe information about Hoyte van Hoytema shooting the film on 35mm film in anamorphic format and IMAX, as well as the use of practical effects and DNEG's contribution to VFX, does not directly relate to the income generated but provides context to its production quality. The initial gross of $681 million is also relevant, showing the film's strong opening performance in theaters using traditional projection methods before transitioning to digital formats.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare prompt template\n",
    "from langchain import PromptTemplate\n",
    "template = \"\"\"\n",
    "<|user|>\n",
    "    Relevant information: {context}\n",
    "    Provide a concise answer the following question using the relevant information provided above: {question}\n",
    "<|end|>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RAG pipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(),\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\":prompt\n",
    "    },\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Execute RAG\n",
    "rag.invoke('Income generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ca5f8-87aa-4a19-aab8-7ba711ea2f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
