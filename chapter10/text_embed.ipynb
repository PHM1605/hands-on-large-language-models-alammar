{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee80e0e-7836-4f31-bdb2-7b72301fb358",
   "metadata": {},
   "source": [
    "# Creating text embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af826c10-dfb3-4f40-b426-6b6eea86dc9f",
   "metadata": {},
   "source": [
    "## Contrastive learning\n",
    "Embedding model classifies if 2 documents are similar or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525bd81-a346-4e97-b835-54a04dd79296",
   "metadata": {},
   "source": [
    "### Generate contrastive examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c42d2a-e3c5-4715-8841-bb4be1ed2689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set using only GPU 0 during training\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46f09bdf-0038-44c4-84d1-24b5dd757be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'One of our number will carry out your instructions minutely.',\n",
       " 'hypothesis': 'A member of my team will execute your orders with immense precision.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Load MNLI dataset from GLUE\n",
    "train_dataset = load_dataset(\n",
    "    \"glue\", \"mnli\", split=\"train\"\n",
    ").select(range(50000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")\n",
    "# 0=entailment; 1=neutral; 2=contradiction\n",
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58114abc-23c5-4008-8f34-bbf4d7e6eee8",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb0bc410-db5f-4f7a-8e1a-30b42ae651e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name google-bert/bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('google-bert/bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6f8513a-0ec2-4a56-bc5c-ddb594633843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "from sentence_transformers import losses\n",
    "train_loss = losses.SoftmaxLoss(\n",
    "    model = embedding_model,\n",
    "    sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),\n",
    "    num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9c78928-0fc3-451b-b0a7-fb8b1c57d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate: we use STSB (Semantic Textual Similarity Benchmark)\n",
    "# including many pairs of sentences with similarity scores in [1..5] range\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# Dataset of <sentence1>,<sentence2>,<label>,<idx> columns\n",
    "val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\") \n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3d6d728-d7e9-422b-9e28-50b439bb6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d90d96d-ae13-4df3-96da-218e72e57d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training arguments\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"base_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True, # use 16bit precision\n",
    "    eval_steps=100,\n",
    "    logging_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9b23933-f57a-4d37-9b63-577c3692f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
      "dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 05:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.080700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.949400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.895900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.851100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.829400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.828600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.818600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.798200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.780800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.742700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.732100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.713500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.751500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.815764824396818, metrics={'train_runtime': 301.414, 'train_samples_per_second': 165.885, 'train_steps_per_second': 5.186, 'total_flos': 0.0, 'train_loss': 0.815764824396818, 'epoch': 1.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Start training\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77b76d9f-67d6-4b2e-be58-9fc4ab7bcf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.5588098432219584, 'spearman_cosine': 0.6210753592157163}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate embedding-model\n",
    "# <pearson-cosine> means 3 steps\n",
    "# 1/ calculate embedding of sentence1 and embedding of sentence 2\n",
    "# 2/ calculate COSINE similarity between them => list of model-scores\n",
    "# 3/ calculate PEARSON between model-scores and human scores (normalized)\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1754aa3",
   "metadata": {},
   "source": [
    "### Evaluate with MTEB (Massive Text Embedding Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75ef6522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model library not recognized, defaulting to Sentence Transformers loader.\n",
      "Evaluating task Banking77Classification: 100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 794.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Choose another evaluation task to check our previous model\n",
    "from mteb import evaluate\n",
    "from mteb.tasks import Banking77Classification\n",
    "\n",
    "results = evaluate(\n",
    "    model=embedding_model,\n",
    "    tasks=[Banking77Classification()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7cb7e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskResult(task_name=Banking77Classification, scores=...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.task_results[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f3f3f",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca69c47f",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8aaef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# Load MNLI dataset from GLUE\n",
    "# 0=similar; 1=neutral; 2=contradiction\n",
    "train_dataset = load_dataset(\n",
    "    \"glue\", \"mnli\", split=\"train\"\n",
    ").select(range(50000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")\n",
    "\n",
    "# Change similar=>1; contradiction / neutral=>0\n",
    "mapping = {2:0, 1:0, 0:1}\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": train_dataset[\"premise\"],\n",
    "    \"sentence2\": train_dataset[\"hypothesis\"],\n",
    "    \"label\": [float(mapping[label]) for label in train_dataset[\"label\"]]\n",
    "})\n",
    "\n",
    "# Create evaluator on val dataset\n",
    "val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]] # similarity:[0..1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89b728fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name google-bert/bert-base-uncased. Creating a new one with mean pooling.\n",
      "                                                                                                                                                               \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 05:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.170400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.160900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.153300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.158900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.149400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.140200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.140500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.15723129792314117, metrics={'train_runtime': 307.0011, 'train_samples_per_second': 162.866, 'train_steps_per_second': 5.091, 'total_flos': 0.0, 'train_loss': 0.15723129792314117, 'epoch': 1.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a different loss function\n",
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "embedding_model = SentenceTransformer(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"cosineloss_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9687dfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.7250536218796055, 'spearman_cosine': 0.7270930231269686}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate - label [0..1] but float (train is binary 0 or 1)\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef22010",
   "metadata": {},
   "source": [
    "### MNR (Multiple Negatives Ranking) loss\n",
    "Definition: loss which uses a question as \"premise\" (anchor) \\\n",
    "-> pairing a related answer as positive \\\n",
    "-> pairing an unrelated answer as negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c225cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50000))\n",
    "mnli = mnli.remove_columns(\"idx\")\n",
    "\n",
    "# original label: 0=similar; 1=neutral; 2=contradiction \n",
    "# => we keep only similar pairs\n",
    "mnli = mnli.filter(lambda x:True if x[\"label\"]==0 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6868cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16875it [00:00, 38341.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare train data\n",
    "train_dataset = {\"anchor\":[], \"positive\":[], \"negative\":[]}\n",
    "soft_negatives = list(mnli[\"hypothesis\"]) # all 2nd sentences\n",
    "random.shuffle(soft_negatives)\n",
    "\n",
    "# similar pairs are \"positive\"; otherwise another sentence would be \"negative\"\n",
    "for row, soft_negatives in tqdm(zip(mnli, soft_negatives)):\n",
    "    train_dataset[\"anchor\"].append(row[\"premise\"])\n",
    "    train_dataset[\"positive\"].append(row[\"hypothesis\"])\n",
    "    train_dataset[\"negative\"].append(soft_negatives)\n",
    "train_dataset = Dataset.from_dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f61f299c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label'],\n",
      "    num_rows: 16875\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(mnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72220a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python310)",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
